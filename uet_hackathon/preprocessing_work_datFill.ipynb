{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##load dataset\n",
    "file = \"data\"\n",
    "\n",
    "train_info_path = file + \"/info_train.csv\"\n",
    "train_work_path = file + \"/dat_fill_work_data/new_work_train.csv\"\n",
    "train_label_path = file + \"/label_train.csv\"\n",
    "\n",
    "test_info_path = file + \"/info_test.csv\"\n",
    "test_work_path = file + \"/dat_fill_work_data/new_work_test.csv\"\n",
    "test_label_path = file + \"/label_test.csv\"\n",
    "\n",
    "\n",
    "## data frame\n",
    "train_info = pd.read_csv(train_info_path)\n",
    "train_work = pd.read_csv(train_work_path)\n",
    "train_label = pd.read_csv(train_label_path)\n",
    "\n",
    "test_info = pd.read_csv(test_info_path)\n",
    "test_work = pd.read_csv(test_work_path)\n",
    "test_label = pd.read_csv(test_label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 247559 entries, 0 to 247558\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   id                  247559 non-null  int64  \n",
      " 1   id_bh               247559 non-null  int64  \n",
      " 2   id_management       247559 non-null  int64  \n",
      " 3   id_office           247559 non-null  object \n",
      " 4   company_type        247559 non-null  int64  \n",
      " 5   job/role            247552 non-null  object \n",
      " 6   from_date           247559 non-null  int64  \n",
      " 7   to_date             247559 non-null  int64  \n",
      " 8   employee_lv         247559 non-null  float64\n",
      " 9   address             247559 non-null  object \n",
      " 10  year_from_date      247559 non-null  int64  \n",
      " 11  year_to_date        247559 non-null  int64  \n",
      " 12  month_from_date     247559 non-null  int64  \n",
      " 13  month_to_date       247559 non-null  int64  \n",
      " 14  num_month_contract  247559 non-null  int64  \n",
      " 15  num_year_contract   247559 non-null  float64\n",
      "dtypes: float64(2), int64(11), object(3)\n",
      "memory usage: 30.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train_work.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## concat \n",
    "work = pd.concat([train_work, test_work],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## format text\n",
    "def preprocess_address(add):\n",
    "    add = re.sub(r'(SÀI GÒN)|(TPHCM)|(HCM)|(TP HCM)','TP HỒ CHÍ MINH',add) #Change some symnonyms\n",
    "    add = re.sub(r'(HN)','HÀ NỘI',add)\n",
    "    add = re.sub(r'(BG)','BẮC GIANG',add)\n",
    "    # Remove some special characters\n",
    "    add = re.sub(r'([\\;\\:\\|•«\\n])', ' ', add)\n",
    "    return add\n",
    "## upper word\n",
    "work['address'] = work['address'].fillna(-99)\n",
    "work['address'] = work.apply(lambda row: str(row.address).upper(), axis = 1)\n",
    "work['address'] = work.apply(lambda row: preprocess_address(row.address), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "def similar(a, b):\n",
    "    a = str(a).upper().strip()\n",
    "    b = str(b).upper().strip()\n",
    "    rp_a = ''\n",
    "    rp_b = ''\n",
    "    for s in a.split(' '):\n",
    "        rp_a += s\n",
    "    for s in b.split(' '):\n",
    "        rp_b += s\n",
    "    return SequenceMatcher(None, rp_a, rp_b).ratio()\n",
    "## province dict\n",
    "province_dict = {\n",
    "    \"An Giang\": 1,\n",
    "    \"Kon Tum\": 33,\n",
    "\"Bà Rịa – Vũng Tàu\": 2,\n",
    "\"Lai Châu\": 34,\n",
    "\"Bắc Giang\"\t: 3,\n",
    "\"Lâm Đồng\": 35,\n",
    "\t\"Bắc Kạn\": 4,\t\n",
    "\t\"Lạng Sơn\": 36,\n",
    "\t\"Bạc Liêu\": 5,\t\n",
    "\t\"Lào Cai\": 37,\n",
    "\t\"Bắc Ninh\": 6, \t\n",
    "\t\"Long An\": 38,\n",
    "\t\"Bến Tre\": 7,\t\n",
    "\t\"Nam Định\": 39,\n",
    "\t\"Bình Định\"\t: 8,\n",
    "\t\"Nghệ An\": 40,\n",
    "\t\"Bình Dương\": 9\t,\n",
    "\t\"Ninh Bình\": 41,\n",
    "\t\"Bình Phước\"\t: 10,\n",
    "\t\"Ninh Thuận\": 42,\n",
    "\t\"Bình Thuận\"\t: 11,\n",
    "\t\"Phú Thọ\": 43,\n",
    "\t\"Cà Mau\"\t: 12,\n",
    "\t\"Phú Yên\": 44,\n",
    "\t\"Cần Thơ\"\t: 13,\n",
    "\t\"Quảng Bình\": 45,\n",
    "\t\"Cao Bằng\"\t: 14,\n",
    "\t\"Quảng Nam\" : 46,\n",
    "\t\"Đà Nẵng\" : 15,\n",
    "\t\"Quảng Ngãi\": 47,\n",
    "\t\"Đắk Lắk\"\t: 16,\n",
    "\t\"Quảng Ninh\" : 48, \n",
    "\t\"Đắk Nông\"\t: 17,\n",
    "\t\"Quảng Trị\": 49,\n",
    "\t\"Điện Biên\"\t: 18,\n",
    "\t\"Sóc Trăng\": 50,\n",
    "\t\"Đồng Nai\"\t: 19,\n",
    "\t\"Sơn La\": 51,\n",
    "\t\"Đồng Tháp\"\t: 20,\n",
    "\t\"Tây Ninh\": 52,\n",
    "\t\"Gia Lai\"\t: 21,\n",
    "\t\"Thái Bình\": 53,\n",
    "\t\"Hà Giang\"\t: 22,\n",
    "\t\"Thái Nguyên\": 54,\n",
    "\t\"Hà Nam\"\t: 23,\n",
    "\t\"Thanh Hóa\": 55,\n",
    "\t\"Hà Nội\"\t: 24,\n",
    "\t\"Thừa Thiên Huế\": 56,\n",
    "\t\"Hà Tĩnh\"\t: 25,\n",
    "\t\"Tiền Giang\": 57,\n",
    "\t\"Hải Dương\"\t: 26,\n",
    "\t\"TP Hồ Chí Minh\" : 58,\n",
    "\t\"Hải Phòng\"\t: 27, \n",
    "\t\"Trà Vinh\": 59,\n",
    "\t\"Hậu Giang\"\t: 28,\n",
    "\t\"Tuyên Quang\": 60, \n",
    "\t\"Hòa Bình\"\t: 29,\n",
    "\t\"Vĩnh Long\": 61,\n",
    "\t\"Hưng Yên\"\t: 30,\n",
    "\t\"Vĩnh Phúc\": 62,\n",
    "\t\"Khánh Hòa\"\t: 31,\n",
    "\t\"Yên Bái\": 63,\n",
    "\t\"Kiên Giang\": 32\t \t \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## caculate similarity\n",
    "for k, v in province_dict.items():\n",
    "    col_name = str(v)\n",
    "    work[col_name] = work.apply(lambda row: similar( row.address, k), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## caculate max similarity\n",
    "province_id = list(range(1,64))\n",
    "province_col_name  = [str(x) for x in province_id]\n",
    "work['max_similar_score'] = work[province_col_name].max(axis= 1)\n",
    "work['work_province_id'] = work[province_col_name].idxmax(axis= 1)\n",
    "\n",
    "## thresh hold = 0.5\n",
    "work['new_work_province_id']  = work.apply(lambda row: row.work_province_id if row.max_similar_score > 0.5 else -999, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. employee_lv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    409842.000000\n",
       "mean          8.089908\n",
       "std           8.250423\n",
       "min        -999.000000\n",
       "25%           5.000000\n",
       "50%           7.000000\n",
       "75%           9.000000\n",
       "max          59.000000\n",
       "Name: employee_lv, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## outlier : -1, 331, 369 - Nan dien la -1\n",
    "work['employee_lv'] = work['employee_lv'].fillna(-1)\n",
    "work['employee_lv'] = work['employee_lv'].apply(lambda x: x if(x < 300) else -1 )\n",
    "work['employee_lv'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. date DA CO ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. job/role"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. company_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k co null\n",
    "work['company_type'] = work['company_type'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. id_management\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. id_office\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = [\n",
    "    'id',\n",
    "    'id_bh',\n",
    "    'new_work_province_id',\n",
    "    'employee_lv',\n",
    "    'from_date','to_date','year_from_date', 'year_to_date', \n",
    "    'month_from_date', 'month_to_date', 'num_year_contract', 'num_month_contract',\n",
    "    \"job/role\", \n",
    "    \"company_type\",\n",
    "    \"id_management\",\n",
    "    \"id_office\"\n",
    "] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 409842 entries, 0 to 162282\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count   Dtype   \n",
      "---  ------                --------------   -----   \n",
      " 0   id                    409842 non-null  int64   \n",
      " 1   id_bh                 409842 non-null  int64   \n",
      " 2   new_work_province_id  409842 non-null  object  \n",
      " 3   employee_lv           409842 non-null  float64 \n",
      " 4   from_date             409842 non-null  int64   \n",
      " 5   to_date               409842 non-null  int64   \n",
      " 6   year_from_date        409842 non-null  int64   \n",
      " 7   year_to_date          409842 non-null  int64   \n",
      " 8   month_from_date       409842 non-null  int64   \n",
      " 9   month_to_date         409842 non-null  int64   \n",
      " 10  num_year_contract     409842 non-null  float64 \n",
      " 11  num_month_contract    409842 non-null  int64   \n",
      " 12  job/role              409832 non-null  object  \n",
      " 13  company_type          409842 non-null  category\n",
      " 14  id_management         409842 non-null  int64   \n",
      " 15  id_office             409842 non-null  object  \n",
      "dtypes: category(1), float64(2), int64(10), object(3)\n",
      "memory usage: 50.4+ MB\n"
     ]
    }
   ],
   "source": [
    "export_work = work[use_cols]\n",
    "export_work.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster job/role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toan\\AppData\\Local\\Temp/ipykernel_20472/453157816.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  export_work['job_role_fillNan'] = export_work['job/role'].fillna(\"none\")\n"
     ]
    }
   ],
   "source": [
    "## cluster job role\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "export_work['job_role_fillNan'] = export_work['job/role'].fillna(\"none\")\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range = (1,2),\n",
    "        min_df=5, \n",
    "    max_df= 0.8, \n",
    "    max_features=1000,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "job_role = export_work['job_role_fillNan'].values\n",
    "X_job_role = vectorizer.fit_transform(job_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 24,  24, 134, ..., 130,  49,  49])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeanModel = KMeans(n_clusters=300, random_state = 2022).fit(X_job_role) \n",
    "kmeanModel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toan\\AppData\\Local\\Temp/ipykernel_20472/3463333387.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  export_work['job_role_encode_knn'] = kmeanModel.labels_\n"
     ]
    }
   ],
   "source": [
    "export_work['job_role_encode_knn'] = kmeanModel.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_export_work = export_work[:len(train_work)]\n",
    "test_export_work = export_work[len(train_work):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'id_bh', 'new_work_province_id', 'employee_lv', 'from_date',\n",
       "       'to_date', 'year_from_date', 'year_to_date', 'month_from_date',\n",
       "       'month_to_date', 'num_year_contract', 'num_month_contract', 'job/role',\n",
       "       'company_type', 'id_management', 'id_office', 'job_role_fillNan',\n",
       "       'job_role_encode_knn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_export_work.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range = (1,2),\n",
    "        min_df=5, \n",
    "    max_df= 0.8, \n",
    "    max_features=1000,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "## TF-IDF + SVD\n",
    "clf = Pipeline([\n",
    "                ('tfidf', vectorizer ),\n",
    "                ('svd', TruncatedSVD(n_components = 128, random_state=42)),\n",
    "                ])\n",
    "clf.fit(train_export_work['job_role_fillNan'].values)\n",
    "train_job = clf.transform(train_export_work['job_role_fillNan'].values)\n",
    "test_job = clf.transform(test_export_work['job_role_fillNan'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409842, 128)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  CONCAT \n",
    "x = np.concatenate((train_job, test_job), axis=0)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8,   8,  70, ..., 231, 170, 170])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeanModel_2 = KMeans(n_clusters=300, random_state = 2022).fit(x) \n",
    "kmeanModel_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toan\\AppData\\Local\\Temp/ipykernel_20472/791237441.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  export_work['job_role_encode_knn_ver2_svd'] = kmeanModel_2.labels_\n"
     ]
    }
   ],
   "source": [
    "export_work['job_role_encode_knn_ver2_svd'] = kmeanModel_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_export_work = export_work[:len(train_work)]\n",
    "test_export_work = export_work[len(train_work):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toan\\anaconda3\\envs\\ml_com\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "C:\\Users\\Toan\\anaconda3\\envs\\ml_com\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "##  encoder cho : id_office , id_management     --> sau do Fill nan -999  \n",
    "from sklearn.preprocessing import  OrdinalEncoder   \n",
    "cols = ['id_office']\n",
    "## replace -999 = Nan\n",
    "train_export_work[cols].replace( -999, np.nan)\n",
    "test_export_work[cols].replace( -999, np.nan)\n",
    "train_export_work[cols].replace( '-999', np.nan)\n",
    "test_export_work[cols].replace( '-999', np.nan)\n",
    "##\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999)\n",
    "train_export_work[cols] = encoder.fit_transform(train_export_work[cols].to_numpy().reshape(-1, 1))\n",
    "test_export_work[cols] = encoder.transform(test_export_work[cols].to_numpy().reshape(-1, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toan\\anaconda3\\envs\\ml_com\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n",
      "C:\\Users\\Toan\\anaconda3\\envs\\ml_com\\lib\\site-packages\\pandas\\core\\frame.py:3678: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[col] = igetitem(value, i)\n"
     ]
    }
   ],
   "source": [
    "cols = ['id_management']\n",
    "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-999)\n",
    "train_export_work[cols] = encoder.fit_transform(train_export_work[cols].to_numpy().reshape(-1, 1))\n",
    "test_export_work[cols] = encoder.transform(test_export_work[cols].to_numpy().reshape(-1, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toan\\AppData\\Local\\Temp/ipykernel_20472/27997092.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_export_work['id_office'] = train_export_work['id_office'].fillna(-999)\n",
      "C:\\Users\\Toan\\AppData\\Local\\Temp/ipykernel_20472/27997092.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_export_work['id_office'] = test_export_work['id_office'].fillna(-999)\n"
     ]
    }
   ],
   "source": [
    "## fill nan -999 id_office             \n",
    "train_export_work['id_office'] = train_export_work['id_office'].fillna(-999)\n",
    "test_export_work['id_office'] = test_export_work['id_office'].fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_export_work.to_csv(r\"data/dat_fill_work_data/processed_train_work.csv\")\n",
    "test_export_work.to_csv(r\"data/dat_fill_work_data/processed_test_work.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98695b7a08c9cf565d1db0672d8357aa94ece3889704c89d84fdcde5b877d054"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ml_com')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
